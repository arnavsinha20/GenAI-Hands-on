{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "03661547",
      "metadata": {
        "id": "03661547"
      },
      "source": [
        "# Daily Horoscope Generator using NLP (27)\n",
        "\n",
        "## Objective\n",
        "To generate a vague but convincing daily horoscope based on a user-provided zodiac sign using a pre-trained language model.\n",
        "\n",
        "## Technology Used\n",
        "- Python\n",
        "- HuggingFace Transformers\n",
        "- DistilGPT-2\n",
        "- PyTorch\n",
        "- Jupyter Notebook\n",
        "\n",
        "## Description\n",
        "This project uses a pre-trained text generation model (DistilGPT-2) to generate horoscope-style text.\n",
        "The model is prompted with zodiac-specific context and produces human-like predictions without any explicit training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dcea5388",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcea5388",
        "outputId": "e5e7e512-6b00-4898-d97b-047cecc9317e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m186.7/186.7 MB\u001b[0m \u001b[31m262.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m290.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m364.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m394.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m393.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m439.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.40.2 requires numpy>=1.17, which is not installed.\n",
            "spanner-graph-notebook 1.1.8 requires numpy, which is not installed.\n",
            "peft 0.18.1 requires numpy>=1.17, which is not installed.\n",
            "spopt 0.7.0 requires numpy>=1.26.0, which is not installed.\n",
            "python-louvain 0.16 requires numpy, which is not installed.\n",
            "accelerate 1.12.0 requires numpy>=1.17, which is not installed.\n",
            "bokeh 3.7.3 requires numpy>=1.16, which is not installed.\n",
            "nibabel 5.3.3 requires numpy>=1.22, which is not installed.\n",
            "hyperopt 0.2.7 requires numpy, which is not installed.\n",
            "holoviews 1.22.1 requires numpy>=1.21, which is not installed.\n",
            "osqp 1.0.5 requires numpy>=1.7, which is not installed.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, which is not installed.\n",
            "flax 0.11.2 requires numpy>=1.23.2; python_version >= \"3.11\", which is not installed.\n",
            "flax 0.11.2 requires numpy>=1.26.0; python_version >= \"3.12\", which is not installed.\n",
            "cudf-cu12 25.10.0 requires numpy<3.0a0,>=1.23, which is not installed.\n",
            "quantecon 0.10.1 requires numpy>=1.17.0, which is not installed.\n",
            "nx-cugraph-cu12 25.10.0 requires numpy<3.0a0,>=1.23, which is not installed.\n",
            "pytensor 2.36.3 requires numpy>=2.0, which is not installed.\n",
            "pysal 25.7 requires numpy>=1.22, which is not installed.\n",
            "chex 0.1.90 requires numpy>=1.24.1, which is not installed.\n",
            "folium 0.20.0 requires numpy, which is not installed.\n",
            "gradio 5.50.0 requires numpy<3.0,>=1.0, which is not installed.\n",
            "tables 3.10.2 requires numpy>=1.20.0, which is not installed.\n",
            "torchtune 0.6.1 requires numpy, which is not installed.\n",
            "mapclassify 2.10.0 requires numpy>=1.26, which is not installed.\n",
            "diffusers 0.36.0 requires numpy, which is not installed.\n",
            "segregation 2.5.3 requires numpy, which is not installed.\n",
            "bigframes 2.31.0 requires numpy>=1.24.0, which is not installed.\n",
            "gymnasium 1.2.3 requires numpy>=1.21.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires numpy>=1.16.4, which is not installed.\n",
            "keras 3.10.0 requires numpy, which is not installed.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, which is not installed.\n",
            "shap 0.50.0 requires numpy>=2, which is not installed.\n",
            "cuml-cu12 25.10.0 requires numpy<3.0a0,>=1.23, which is not installed.\n",
            "orbax-checkpoint 0.11.31 requires numpy, which is not installed.\n",
            "datasets 4.0.0 requires numpy>=1.17, which is not installed.\n",
            "pymc 5.27.0 requires numpy>=1.25.0, which is not installed.\n",
            "dask-cudf-cu12 25.10.0 requires numpy<3.0a0,>=1.23, which is not installed.\n",
            "tensorflow-datasets 4.9.9 requires numpy, which is not installed.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, which is not installed.\n",
            "spacy 3.8.11 requires numpy>=1.19.0; python_version >= \"3.9\", which is not installed.\n",
            "torchvision 0.24.0+cu126 requires numpy, which is not installed.\n",
            "librosa 0.11.0 requires numpy>=1.22.3, which is not installed.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, which is not installed.\n",
            "geemap 0.35.3 requires numpy, which is not installed.\n",
            "libpysal 4.14.1 requires numpy>=1.26.0, which is not installed.\n",
            "langchain-core 1.2.7 requires packaging<26.0.0,>=23.2.0, but you have packaging 26.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.2.2+cpu which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.2.2+cpu which is incompatible.\n",
            "sentence-transformers 5.2.0 requires transformers<6.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m294.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m238.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m145.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m330.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m377.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m621.4/621.4 kB\u001b[0m \u001b[31m353.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m237.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m352.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m453.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m368.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m377.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m341.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m147.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m370.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m371.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m312.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m357.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m176.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m367.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m146.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m359.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m391.4/391.4 kB\u001b[0m \u001b[31m446.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m450.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m229.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m413.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m398.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m93.8/93.8 kB\u001b[0m \u001b[31m353.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 9.9.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain-core 1.2.7 requires packaging<26.0.0,>=23.2.0, but you have packaging 26.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.2.1 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.2.2+cpu which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.2.2+cpu which is incompatible.\n",
            "sentence-transformers 5.2.0 requires transformers<6.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q --no-cache-dir --force-reinstall --index-url https://download.pytorch.org/whl/cpu torch==2.2.2\n",
        "!pip install -q --no-cache-dir --force-reinstall transformers==4.40.2 ipywidgets==8.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f198a2cb",
      "metadata": {
        "id": "f198a2cb"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7b72280d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b72280d",
        "outputId": "6df88589-7adc-4071-b76b-04743036c9c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-5): 6 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model_name = \"distilgpt2\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7791312e",
      "metadata": {
        "id": "7791312e"
      },
      "outputs": [],
      "source": [
        "zodiac_traits = {\n",
        "    \"Aries\": \"bold and energetic\",\n",
        "    \"Taurus\": \"patient and practical\",\n",
        "    \"Gemini\": \"curious and expressive\",\n",
        "    \"Cancer\": \"emotional and caring\",\n",
        "    \"Leo\": \"confident and charismatic\",\n",
        "    \"Virgo\": \"analytical and disciplined\",\n",
        "    \"Libra\": \"balanced and diplomatic\",\n",
        "    \"Scorpio\": \"intense and intuitive\",\n",
        "    \"Sagittarius\": \"adventurous and optimistic\",\n",
        "    \"Capricorn\": \"ambitious and focused\",\n",
        "    \"Aquarius\": \"innovative and independent\",\n",
        "    \"Pisces\": \"dreamy and empathetic\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "92f21485",
      "metadata": {
        "id": "92f21485"
      },
      "outputs": [],
      "source": [
        "def generate_horoscope(zodiac):\n",
        "    if zodiac not in zodiac_traits:\n",
        "        return f\"Sorry, '{zodiac}' is not a recognized zodiac sign. Please enter a valid one (e.g., Aries, Taurus, etc.).\"\n",
        "\n",
        "    trait = zodiac_traits.get(zodiac, \"unique and special\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Daily Horoscope\n",
        "Zodiac Sign: {zodiac}\n",
        "Personality Traits: {trait}\n",
        "Prediction:\n",
        "\"\"\"\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=120,\n",
        "        temperature=0.9,\n",
        "        top_p=0.95,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    horoscope = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return horoscope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "bb51b97f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb51b97f",
        "outputId": "e9380b38-7489-4096-81cc-8cdd79b610cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your zodiac sign: Virgo\n",
            "\n",
            "沐ｮ Your Daily Horoscope 沐ｮ\n",
            "\n",
            "\n",
            "Daily Horoscope\n",
            "Zodiac Sign: Virgo\n",
            "Personality Traits: analytical and disciplined\n",
            "Prediction:\n",
            "This picture is very impressive, but I would assume we are going to see more of this in a year.\n",
            "When you get to the frontiers, where do you start?\n",
            "The great thing about this picture is the sheer size, which shows that there are many other possibilities to it. The colors are much larger, so the color is very different from the ones that are on the right hand side, so when you look at this picture of the sky, you can\n"
          ]
        }
      ],
      "source": [
        "zodiac = input(\"Enter your zodiac sign: \").capitalize()\n",
        "\n",
        "print(\"\\n沐ｮ Your Daily Horoscope 沐ｮ\\n\")\n",
        "print(generate_horoscope(zodiac))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce4c8f3",
      "metadata": {
        "id": "5ce4c8f3"
      },
      "source": [
        "### Sample Output\n",
        "\n",
        "沐ｮ Your Daily Horoscope 沐ｮ\n",
        "\n",
        "Daily Horoscope  \n",
        "Zodiac Sign: Leo  \n",
        "Personality Traits: confident and charismatic  \n",
        "\n",
        "Prediction:  \n",
        "Today brings a moment of clarity in your personal decisions.  \n",
        "You may feel motivated to take initiative, but patience will be equally important.  \n",
        "Trust your instincts and allow things to unfold naturally.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e9bfc48",
      "metadata": {
        "id": "3e9bfc48"
      },
      "source": [
        "## Conclusion\n",
        "This notebook demonstrates the use of a pre-trained NLP model for creative text generation.\n",
        "By leveraging DistilGPT-2 and prompt engineering, the system produces realistic horoscope predictions\n",
        "without requiring custom training data.\n",
        "\n",
        "The project highlights practical applications of Natural Language Processing and text generation models.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}